# -*- coding: utf-8 -*-

import fnmatch
import json
import shutil
import uuid
from pathlib import Path, PurePath
from posixpath import join as posixjoin
from typing import Optional, List, Union, Sequence

from tailor.internal.storage.storage_provider import StorageProvider
from tailor.internal.utils import get_logger
from tailor.internal.utils import list_files


class FileSystemStorageProvider(StorageProvider):

    def __init__(self, path: Union[Path, str]):
        self.logger = get_logger('FileSystemStorageProvider')
        self.path = Path(path).absolute()

    def __basedir(self, storage_key):
        return self.path / storage_key

    def __non_user_dir(self, storage_key):
        return self.__basedir(storage_key) / '_'

    def __tags_dir(self, storage_key):
        return self.__non_user_dir(storage_key) / 'tags'

    def __scope_prefixes_dir(self, storage_key):
        return self.__non_user_dir(storage_key) / 'scope_prefixes'

    def __filenames_rel_to_basedir(self, storage_key):
        basedir = self.__basedir(storage_key)
        all_relnames = [p.relative_to(basedir).as_posix()
                        for p in list_files(path=basedir) if p.is_file()]
        return [rn for rn in all_relnames if not rn.startswith('_/')]

    def __initialize_storage_key(self, storage_key):
        self.__basedir(storage_key).mkdir()
        self.__non_user_dir(storage_key).mkdir()
        self.__tags_dir(storage_key).mkdir()
        self.__scope_prefixes_dir(storage_key).mkdir()

    def _add_tag(self, storage_key, tag, paths):
        with open(self.__tags_dir(storage_key) / tag, 'w') as fp:
            json.dump(paths, fp)

    def _load_tags(self, storage_key):
        tags = {}
        for p in self.__tags_dir(storage_key).iterdir():
            with open(p, 'r') as fp:
                tags[p.name] = json.load(fp)
        return tags

    def _add_scope_prefix(self, storage_key, scope_prefix):
        identifier = str(uuid.uuid1())
        with open(self.__scope_prefixes_dir(storage_key) / identifier, 'w') as fp:
            json.dump(scope_prefix, fp)

    def _load_scope_prefixes(self, storage_key):
        scope_prefixes = []
        for p in self.__scope_prefixes_dir(storage_key).iterdir():
            with open(p, 'r') as fp:
                scope_prefixes.append(json.load(fp))
        return scope_prefixes

    def new_storage_key(self) -> str:
        storage_key = str(uuid.uuid4())
        self.__initialize_storage_key(storage_key)
        return storage_key

    def get_tags(self, storage_key: str) -> dict:
        tags = self._load_tags(storage_key)
        for tag in tags:
            if tags[tag] == '*SCOPED*':
                tags[tag] = self.get_file_list(storage_key, name_filter=tag + '/*')
        return tags

    def get_detailed_file_list(self, storage_key: str, name_filter: str = '*') -> List[dict]:
        file_names = fnmatch.filter(self.__filenames_rel_to_basedir(storage_key),
                                    name_filter)

        return [{'file_name': filename, 'url': None} for filename in file_names]

    def upload(
            self,
            storage_key: str,
            filename: Union[str, Sequence[str]],
            path_prefix: str = '',
            tag: Optional[str] = None
    ) -> List[str]:

        basedir = self.__basedir(storage_key)
        if not isinstance(filename, str):
            fnames = []
            for fn in filename:
                fnames.append(self.upload(storage_key, fn, path_prefix, tag))
            if tag:
                self._add_tag(storage_key, tag, fnames)
            return fnames
        else:
            filename = Path(filename)
            if tag:
                dest = basedir / path_prefix / tag / filename.name
            else:
                dest = basedir / path_prefix / filename.name
            dest.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy(filename, dest)
            fname = dest.relative_to(basedir).as_posix()
            if tag:
                self._add_tag(storage_key, tag, fname)
            return fname

    def upload_scoped(
            self,
            storage_key: str,
            filename: Union[str, Sequence[str]],
            tag: str,
            scope_indices: List[int],
            path_prefix: str = ''
    ) -> List[str]:

        scope_prefix = tag
        for i in scope_indices:
            scope_prefix += '/' + str(i)
        fnames = self.upload(storage_key, filename, scope_prefix)
        self._add_tag(storage_key, tag, '*SCOPED*')  # add/overwrite tag
        self._add_scope_prefix(storage_key, scope_prefix)
        return fnames

    def download(
            self,
            storage_key: str,
            fname_or_tag: Union[str, Sequence[str]],
            target_dir: str = '.',
            filename_prefix: str = ''
    ) -> List[str]:

        # get storage key
        # AGJ: Is this necessary? when is storage_key not str?
        if not isinstance(storage_key, str):
            storage_key = storage_key.storage_key

        tags = self.get_tags(storage_key)
        basedir = self.__basedir(storage_key)

        if not isinstance(fname_or_tag, str):
            # fname_or_tag is sequence of filenames or tags
            # use recursive pattern
            fnames = []
            for fn in fname_or_tag:
                downloaded = self.download(storage_key, fn, target_dir)
                if isinstance(downloaded, list):
                    fnames.extend(downloaded)
                else:
                    fnames.append(downloaded)
            return fnames

        elif fname_or_tag in tags:
            # fname_or_tag is a tag
            if self._load_tags(storage_key)[fname_or_tag] == '*SCOPED*':
                return self.download_scoped(storage_key, fname_or_tag, [], target_dir)
            return self.download(storage_key, tags[fname_or_tag], target_dir)
        else:
            # fname_or_tag is a filename
            fname_or_tag = Path(fname_or_tag)
            source = basedir / fname_or_tag

            dest = Path(target_dir) / (filename_prefix + fname_or_tag.name)
            dest.parent.mkdir(parents=True, exist_ok=True)

            if source.is_file():
                shutil.copy(source, dest)
                return dest.absolute().as_posix()
            else:
                raise ValueError(
                    'File {} not found in directory {}'
                    ''.format(fname_or_tag, basedir))

    def download_scoped(
            self,
            storage_key: str,
            fname_or_tag: str,
            scope_indices: List[int],
            target_dir: str = '.'
    ) -> List[str]:

        if fname_or_tag in self.get_file_list(storage_key):

            fname = fname_or_tag
            p = PurePath(fname)
            scope_prefix = p.parent.as_posix()
            scope_prefixes = self._load_scope_prefixes(storage_key)
            if scope_prefix == '.' or scope_prefix not in scope_prefixes:
                # file not uploaded from a duplicate, do standard download
                return self.download(storage_key, fname, target_dir)
            else:
                # scoped_target_dir = posixjoin(
                #     target_dir, self._get_target_dir(scope_prefix, scope_indices))
                # return self.download(storage_key, fname, scoped_target_dir)
                filename_prefix = self._get_filename_prefix(scope_prefix, scope_indices)
                return self.download(storage_key, fname, '.', filename_prefix)

        elif fname_or_tag in self.get_tags(storage_key):

            tag = fname_or_tag
            if not self._load_tags(storage_key)[tag] == '*SCOPED*':
                # tag not uploaded from duplicate
                # do standard download
                return self.download(storage_key, fname_or_tag, target_dir)

            fnames = self.get_scoped_file_list(storage_key, tag, scope_indices)

            downloaded_fnames = []
            for fname in fnames:
                downloaded_fnames.append(self.download_scoped(
                    storage_key, fname, scope_indices, target_dir))
            return downloaded_fnames
        else:
            raise ValueError(
                f'File or tag "{fname_or_tag}" not found in storage resource with key '
                f'{storage_key}'
            )

    def delete_all(self, storage_key: str) -> None:
        basedir = self.__basedir(storage_key)
        shutil.rmtree(basedir, ignore_errors=True)
        # in case the basedir wasn't deleted
        try:
            basedir.rmdir()
        except FileNotFoundError:
            pass  # this is fine
        except:
            # could not delete everything
            self.logger.warn("Unknown error deleting file tree", exc_info=1)
