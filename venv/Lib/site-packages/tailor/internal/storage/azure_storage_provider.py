# -*- coding: utf-8 -*-
import fnmatch
import json
import uuid
import re
from datetime import datetime, timedelta
from os import getenv
from os.path import basename
from pathlib import PurePath, Path
from posixpath import join as posixjoin
from typing import Optional, List, Union, Sequence
from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, generate_blob_sas, BlobSasPermissions
from azure.core.exceptions import ResourceExistsError, ResourceNotFoundError
from tailor.internal.storage.storage_provider import StorageProvider
from tailor.internal.utils import get_logger


class BlobStorageProvider(StorageProvider):
    def __init__(self, container_name: str):
        self.logger = get_logger('az_blob_storage')
        self.container_name: str = container_name
        self.client: BlobServiceClient = self.__connect()
        self.container: ContainerClient = self.__get_or_create_container()

    @staticmethod
    def __connection_string() -> str:
        """str: Retrieve Azure storage connection string."""
        cstr = getenv('AZURE_STORAGE_CONNECTION_STRING')
        if cstr is None:
            raise ConnectionError(f"Missing connection string. Set the Azure connection string"
                                  f"as the environmental variable 'AZURE_STORAGE_CONNECTION_STRING'.")
        else:
            return cstr

    def __connect(self) -> BlobServiceClient:
        """BlobServiceClient: Connect to blob storage account."""
        try:
            client: BlobServiceClient = BlobServiceClient.from_connection_string(self.__connection_string())
        except ValueError:
            raise ConnectionError(f"Bad connection string '{self.__connection_string()}'.")
        else:
            return client

    def __get_or_create_container(self) -> ContainerClient:
        """ContainerClient: Get container by name, create it if it does not exist."""
        container: ContainerClient = self.client.get_container_client(self.container_name)
        try:
            container.create_container()
        except ResourceExistsError:
            pass
        finally:
            return container

    def __key_exists(self, key: str) -> bool:
        return key in list([_.name for _ in self.container.list_blobs()])

    def __basedir(self, key: str) -> str:
        return key + '/'

    def __non_user_dir(self, key: str):
        return self.__basedir(key) + '_/'

    def __tags_dir(self, key: str) -> str:
        return self.__non_user_dir(key) + 'tags/'

    def __scope_prefixes_dir(self, key: str) -> str:
        return self.__non_user_dir(key) + 'scope_prefixes/'

    def __add_tag(self, key: str, tag: str, paths):
        self.container.upload_blob(self.__tags_dir(key) + tag, data=json.dumps(paths).encode())

    def __load_tags(self, key: str) -> dict:
        tags = dict()
        for _ in self.container.list_blobs(name_starts_with=self.__tags_dir(key)):
            tag = _.name.replace(self.__tags_dir(key), '')  # remove the prefix/directory
            blob = self.container.download_blob(_)
            tags[tag] = json.loads(blob.readall().decode())
        return tags

    def __add_scope_prefix(self, key: str, prefix: str):
        identifier = str(uuid.uuid1())
        self.container.upload_blob(self.__scope_prefixes_dir(key) + identifier, data=json.dumps(prefix).encode())

    def __load_scope_prefixes(self, key: str) -> list:
        scope_prefixes = list()
        for _ in self.container.list_blobs(name_starts_with=self.__scope_prefixes_dir(key)):
            blob = self.container.download_blob(_.name)
            scope_prefixes.append(json.loads(blob.readall().decode()))

        return scope_prefixes

    def __create_presigned_url(self, key: str, expires_in_hours: int = 1) -> str:
        sas_token = generate_blob_sas(
            account_name=self.account_name,
            account_key=self.account_key,
            container_name=self.container_name,
            blob_name=key,
            permission=BlobSasPermissions(read=True),
            expiry=datetime.utcnow() + timedelta(hours=expires_in_hours)
        )
        blob: BlobClient = self.container.get_blob_client(key)
        return f"{blob.url}?{sas_token}"

    def __everything(self, key) -> List[str]:
        """list: Everything in base directory."""
        return [_.name for _ in self.container.list_blobs(name_starts_with=self.__basedir(key))]

    @property
    def account_key(self) -> str:
        """str: Storage account key."""
        pattern = "AccountKey=(?P<account_key>[^;]*)"
        match = re.search(pattern, self.__connection_string())
        if match is not None:
            return match.groupdict().get("account_key", "")
        else:
            return ""

    @property
    def account_name(self) -> str:
        """str: Storage account name."""
        pattern = "AccountName=(?P<account_name>[^;]*)"
        match = re.search(pattern, self.__connection_string())
        if match is not None:
            return match.groupdict().get("account_name", "")
        else:
            return ""

    def new_storage_key(self) -> str:
        return str(uuid.uuid4())

    def get_tags(self, key: str) -> dict:
        tags = self.__load_tags(key)
        for tag in tags:
            if tags[tag] == '*SCOPED*':
                tags[tag] = self.get_file_list(key, name_filter=tag + '/*')
        return tags

    def get_detailed_file_list(self, key: str, name_filter: str = '*') -> List[dict]:
        """list: Name and presigned URL for blobs mathing name filter"""
        files = list()
        for path in self.__everything(key):
            rpath = Path(path).relative_to(self.__basedir(key)).as_posix()
            if rpath is not None and rpath != "" and not rpath.startswith('_/') and fnmatch.fnmatch(rpath, name_filter):
                files.append(dict(file_name=rpath, url=self.__create_presigned_url(path)))

        return files

    def get_scoped_file_list(self, key: str, tag: str, scope_indices: List[int]) -> List[str]:

        def is_in_scope(file_name, scope_prefix):
            file_name_prefix = PurePath(file_name).parent.as_posix()
            if file_name_prefix.startswith(scope_prefix):
                return True
            if scope_prefix.startswith(file_name_prefix):
                return True
            return False

        if not self.__load_tags(key)[tag] == '*SCOPED*' or not scope_indices:
            file_list = self.get_tags(key)[tag]
            # file_list can either be str og list, ensure list:
            return file_list if isinstance(file_list, list) else [file_list]

        scope_prefix = tag
        for scope_index in scope_indices:
            scope_prefix += '/' + str(scope_index)

        candidates = self.get_file_list(key, tag + '/*')
        matched = []
        for c in candidates:
            if is_in_scope(c, scope_prefix):
                matched.append(c)
        return matched

    def upload(self, key: str, filename: Union[str, Sequence[str]], path_prefix: str = '',
               tag: Optional[str] = None) -> List[str]:

        if not isinstance(filename, str):
            filenames = filename
        else:
            filenames = list([filename])

        fnames = list()

        for filename in filenames:
            base_filename = basename(filename)

            if tag is not None:
                fname = posixjoin(path_prefix, tag, base_filename)
            else:
                fname = posixjoin(path_prefix, base_filename)

            fnames.append(fname)

            with open(filename, "rb") as data:
                self.container.upload_blob(posixjoin(key, fname), data)

        if tag:
            self.__add_tag(key, tag, fnames)

        return fnames

    def upload_scoped(self, key: str, filename: Union[str, Sequence[str]], tag: str, scope_indices: List[int],
                      path_prefix: str = '') -> List[str]:

        scope_prefix = tag
        for i in scope_indices:
            scope_prefix += '/' + str(i)
        fnames = self.upload(key, filename, scope_prefix)
        self.__add_tag(key, tag, '*SCOPED*')  # add/overwrite tag
        self.__add_scope_prefix(key, scope_prefix)
        return fnames

    def download(self, key: str, fname_or_tag: Union[str, Sequence[str]], target_dir: str = '.') -> List[str]:

        tags = self.get_tags(key)
        if not isinstance(fname_or_tag, str):
            # fname_or_tag is sequence of filenames or tags
            fnames = list()
            for fn in fname_or_tag:
                downloaded = self.download(key, fn, target_dir)
                fnames.extend(downloaded)
            return fnames
        elif fname_or_tag in tags:
            if self.__load_tags(key)[fname_or_tag] == '*SCOPED*':
                return self.download_scoped(key, fname_or_tag, list(), target_dir)
            return self.download(key, tags[fname_or_tag], target_dir)
        else:
            filename = posixjoin(self.__basedir(key), fname_or_tag)
            local_filename = Path(target_dir) / basename(fname_or_tag)
            if self.__key_exists(filename):
                local_filename.parent.mkdir(parents=True, exist_ok=True)
                blob_client = self.container.get_blob_client(filename)
                with open(local_filename.as_posix(), "wb") as target_file:
                    target_file.write(blob_client.download_blob().readall())

                return list([local_filename, ])
            else:
                raise ValueError(f"File {fname_or_tag} not found under storage key {key}")

    def download_scoped(self, storage_key: str, fname_or_tag: str, scope_indices: List[int], target_dir: str = '.')\
            -> List[str]:

        if fname_or_tag in self.get_file_list(storage_key):

            fname = fname_or_tag
            p = PurePath(fname)
            scope_prefix = p.parent.as_posix()
            scope_prefixes = self.__load_scope_prefixes(storage_key)
            if scope_prefix == '.' or scope_prefix not in scope_prefixes:
                # file not uploaded from a duplicate, do standard download
                return self.download(storage_key, fname, target_dir)
            else:
                scoped_target_dir = posixjoin(
                    target_dir, self._get_target_dir(scope_prefix, scope_indices))
                return self.download(storage_key, fname, scoped_target_dir)

        elif fname_or_tag in self.get_tags(storage_key):

            tag = fname_or_tag
            if not self.__load_tags(storage_key)[tag] == '*SCOPED*':
                # tag not uploaded from duplicate
                # do standard download
                return self.download(storage_key, fname_or_tag, target_dir)

            fnames = self.get_scoped_file_list(storage_key, tag, scope_indices)

            downloaded_fnames = []
            for fname in fnames:
                downloaded_fnames.extend(self.download_scoped(
                    storage_key, fname, scope_indices, target_dir))
            return downloaded_fnames
        else:
            raise ResourceNotFoundError(
                f'File or tag "{fname_or_tag}" not found in storage resource with key {storage_key}')

    def delete_all(self, storage_key: str) -> bool:
        try:
            for blob in self.container.list_blobs(name_starts_with=self.__basedir(storage_key)):
                self.container.delete_blob(blob)
        except Exception:
            return False
        else:
            return True
