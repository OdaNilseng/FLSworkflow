# -*- coding: utf-8 -*-
from collections import defaultdict
from datetime import datetime
from typing import Optional

from tailor.internal.domain.mongo import BaseModel
from tailor.internal.domain.postgres.models import UserIdProvider
from tailor.internal.domain.single_task import SingleTaskState


class ExternalReferencesModel:

    def __init__(self, project_ref: str, user_ref: str, reference_provider: str):
        self.project_ref = project_ref
        self.user_ref = user_ref
        self.reference_provider = reference_provider

    @staticmethod
    def create_from_config_file(project_name: Optional[str] = None):
        from tailor.config import config
        return ExternalReferencesModel(
            # TODO also: security considerations, APIKEY? Token fra AWS?
            # Variations:
            #  local-only instance (typically Entail-employee)
            #  remote-controlled instance (Tailor/web)
            #  third-party remote-controlled-instance (Inquire)
            project_name or config['DEFAULT_PROJECT'],
            config['USERNAME'],
            UserIdProvider.LOCAL_CONFIG_FILE.name)

    def to_dict(self):
        d = {
            'project_ref': self.project_ref,
            'user_ref': self.user_ref,
            'reference_provider': self.reference_provider
        }
        return d

    @classmethod
    def from_dict(cls, d):
        return ExternalReferencesModel(
            d['project_ref'],
            d['user_ref'],
            d['reference_provider']
        )

    def __eq__(self, other):
        if isinstance(other, self.__class__):
            return self.__dict__ == other.__dict__
        else:
            return False

    def __hash__(self):
        return hash(tuple(sorted(self.__dict__.items())))


class WorkflowModel(BaseModel):

    def __init__(self, wf_id, name: str, wf_def, links,
                 context_id,
                 task_states,
                 external_references: ExternalReferencesModel,
                 worker=None,
                 created_on=None,
                 updated_on=None,
                 ):
        self.id = wf_id
        self.name = name
        self.wf_def = wf_def
        self.links = links  # parent: children links
        self.external_references = external_references

        self.context_id = context_id

        self.worker = worker

        self.task_states = task_states

        self.created_on = created_on or datetime.utcnow()
        self.updated_on = updated_on or datetime.utcnow()

    @property
    def all_task_ids(self):
        all_ids = list(self.links.keys())
        for v in self.links.values():
            all_ids.extend(v)
            return list(set(all_ids))

    @property
    def root_task_ids(self):
        all_ids = set(self.all_task_ids)
        child_ids = set(self.parent_links.keys())
        root_ids = all_ids.difference(child_ids)
        return list(root_ids)

    @property
    def leaf_task_ids(self):
        leaf_ids = []
        for pid, children in self.links.items():
            if len(children) == 0:
                leaf_ids.append(pid)
        return leaf_ids

    @property
    def parent_links(self):
        # child: parents links
        # this does not include root tasks...
        c_p_links = defaultdict(list)
        for p, c in self.links.items():
            for ci in c:
                c_p_links[ci].append(p)
        return dict(c_p_links)

    @property
    def state(self) -> SingleTaskState:
        states = set(self.task_states.values()) or set()
        aggregated_state = SingleTaskState.READY

        if all(s == SingleTaskState.COMPLETED for s in states):
            aggregated_state = SingleTaskState.COMPLETED
        elif all(s == SingleTaskState.ARCHIVED for s in states):
            aggregated_state = SingleTaskState.ARCHIVED
        elif all(s == SingleTaskState.WAITING for s in states):
            # Note: the current design sets 1+ task to ready initially,
            # so this case will not happen unless there is a bug
            aggregated_state = SingleTaskState.WAITING
        elif any(s == SingleTaskState.STOPPED for s in states):
            aggregated_state = SingleTaskState.STOPPED
        elif any(s == SingleTaskState.FAILED for s in states):
            aggregated_state = SingleTaskState.FAILED
        elif any(s == SingleTaskState.RUNNING or s == SingleTaskState.COMPLETED for s in
                 states):
            aggregated_state = SingleTaskState.RUNNING
        elif any(s == SingleTaskState.RESERVED for s in states):
            # Note: we've already checked if any task is running
            # here, no task has been processed yet, only reserved by a worker
            aggregated_state = SingleTaskState.RESERVED

        return aggregated_state

    def to_dict(self):
        d = {
            'id': self.id,
            'name': self.name,
            'wf_def': self.dict_keys_int_to_str(self.wf_def),
            'links': self.dict_keys_int_to_str(self.links),
            'context_id': self.context_id,
            'task_states': SingleTaskState.to_dict(self.task_states),
            'worker': self.worker,
            'created_on': self.created_on,
            'updated_on': self.updated_on,
            'external_references': self.external_references.to_dict()
        }
        return d

    @classmethod
    def from_dict(cls, d):
        return WorkflowModel(
            wf_id=d['id'],
            name=d['name'],
            wf_def=BaseModel.dict_keys_str_to_int(d['wf_def']),
            links=BaseModel.dict_keys_str_to_int(d['links']),
            context_id=d['context_id'],
            task_states=SingleTaskState.from_dict(d['task_states']),
            worker=d['worker'],
            created_on=d['created_on'],
            updated_on=d['updated_on'],
            external_references=ExternalReferencesModel.from_dict(
                d['external_references'])
        )
